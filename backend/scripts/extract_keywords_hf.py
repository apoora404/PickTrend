"""
HuggingFace KLUE + 위키피디아에서 키워드 자동 추출

라이선스:
- KLUE 데이터셋: CC-BY-SA-4.0 (https://klue-benchmark.com/)
- 한국어 위키피디아: CC-BY-SA-3.0 (https://ko.wikipedia.org/)
- KcBERT 토크나이저: Apache 2.0 (https://github.com/Beomi/KcBERT)

사용법:
    python scripts/extract_keywords_hf.py
"""

import re
import sys
from pathlib import Path
from collections import defaultdict
from typing import Dict, Set, List

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import wikipediaapi
except ImportError:
    print("Error: wikipedia-api 패키지가 설치되지 않았습니다.")
    print("pip install wikipedia-api 실행 후 다시 시도하세요.")
    sys.exit(1)


# 위키피디아 카테고리 → MemeBoard 카테고리
# 각 카테고리에서 최대 50개 문서 제목 추출
WIKI_CATEGORY_MAP = {
    # politics (목표: 250개)
    "politics": [
        "대한민국의_정치인",
        "대한민국의_대통령",
        "대한민국의_총리",
        "대한민국_국회의원",
        "대한민국의_정당",
        "대한민국의_정치_사건",
        "한국의_선거",
    ],
    # sports (목표: 300개)
    "sports": [
        "대한민국의_축구_선수",
        "대한민국의_야구_선수",
        "대한민국의_농구_선수",
        "대한민국의_배구_선수",
        "대한민국의_골프_선수",
        "대한민국의_격투기_선수",
        "대한민국의_올림픽_금메달리스트",
        "KBO_리그",
        "K리그1",
        "프리미어_리그",
        "라리가",
        "메이저_리그_베이스볼",
        "분데스리가",
        "세리에_A",
    ],
    # celebrity (목표: 350개)
    "celebrity": [
        "대한민국의_남자_배우",
        "대한민국의_여자_배우",
        "대한민국의_남자_가수",
        "대한민국의_여자_가수",
        "대한민국의_아이돌_그룹",
        "대한민국의_보이_밴드",
        "대한민국의_걸_그룹",
        "대한민국의_힙합_음악가",
        "대한민국의_방송인",
        "대한민국의_희극인",
        "대한민국의_영화",
        "대한민국의_텔레비전_프로그램",
    ],
    # stock (목표: 250개)
    "stock": [
        "대한민국의_기업",
        "코스피_상장_기업",
        "코스닥_상장_기업",
        "대한민국의_은행",
        "대한민국의_증권_회사",
        "암호화폐",
        "부동산",
    ],
    # game (목표: 350개)
    "game": [
        "비디오_게임",
        "온라인_게임",
        "모바일_게임",
        "대한민국의_비디오_게임",
        "e스포츠",
        "대한민국의_프로게이머",
        "일본의_애니메이션",
        "만화",
        "웹툰",
        "일본의_만화",
        "대한민국의_만화가",
    ],
}

# 제외할 일반적인 단어들
EXCLUDED_WORDS = {
    # 일반 명사/조사
    "것", "수", "등", "그", "이", "더", "년", "월", "일", "곳", "때", "안",
    "중", "위", "내", "후", "전", "간", "대", "말", "우리", "나",
    "그것", "이것", "저것", "여기", "거기", "저기", "오늘", "내일", "어제",
    # 너무 일반적인 단어
    "목록", "분류", "문서", "문서들", "참조", "같이", "보기", "관련",
    "위키백과", "한국", "대한민국", "한국의", "대한민국의", "역사", "문화",
    # 위키백과 메타데이터
    "년생", "년대", "세기", "출신", "사람", "인물", "출생", "사망",
}


def extract_from_wikipedia() -> Dict[str, Set[str]]:
    """한국어 위키피디아 카테고리에서 문서 제목 추출"""
    print("위키피디아 카테고리 탐색 중...")

    extracted: Dict[str, Set[str]] = defaultdict(set)

    # 위키피디아 API 초기화
    wiki = wikipediaapi.Wikipedia(
        user_agent="MemeBoard/1.0 (https://github.com/apoora404/PickTrend)",
        language="ko"
    )

    for memeboard_cat, wiki_cats in WIKI_CATEGORY_MAP.items():
        print(f"\n[{memeboard_cat}]")
        for wiki_cat in wiki_cats:
            try:
                cat_page = wiki.page(f"분류:{wiki_cat}")
                if not cat_page.exists():
                    print(f"  {wiki_cat}: 존재하지 않음")
                    continue

                # 카테고리 내 문서 제목 추출 (최대 50개)
                count = 0
                for member in cat_page.categorymembers.values():
                    if member.ns == 0:  # 일반 문서만 (ns=0)
                        title = member.title
                        # 괄호 제거 (예: "이름 (배우)" → "이름")
                        clean_title = re.sub(r'\s*\([^)]*\)\s*', '', title).strip()

                        if is_valid_keyword(clean_title):
                            extracted[memeboard_cat].add(clean_title)
                            count += 1

                    if count >= 50:  # 카테고리당 최대 50개
                        break

                print(f"  {wiki_cat}: {count}개")

            except Exception as e:
                print(f"  {wiki_cat}: 오류 - {e}")

        print(f"  → {memeboard_cat} 총: {len(extracted[memeboard_cat])}개")

    return extracted


def is_valid_keyword(word: str) -> bool:
    """유효한 키워드인지 검사"""
    if not word:
        return False

    # 2글자 이상
    if len(word) < 2:
        return False

    # 너무 긴 것 제외 (문장일 가능성)
    if len(word) > 20:
        return False

    # 한글 또는 영어 포함
    if not (re.search(r'[가-힣]', word) or re.search(r'[a-zA-Z]', word)):
        return False

    # 숫자만 있는 경우 제외
    if word.isdigit():
        return False

    # 제외 목록 체크
    if word in EXCLUDED_WORDS:
        return False

    # "년", "월", "일"로 시작하는 날짜 관련 제외
    if re.match(r'^\d+년', word) or re.match(r'^\d+월', word):
        return False

    return True


def load_existing_keywords() -> Dict[str, Set[str]]:
    """기존 keywords.py 원본에서 키워드 로드 (백업 필요)"""
    print("\n기존 키워드 로딩 중...")

    # 원본 키워드 (하드코딩 - 백업용)
    # 실제로는 git에서 복원하거나 백업 파일 사용
    existing: Dict[str, Set[str]] = {
        "politics": {
            "국힘", "국민의힘", "민주당", "더불어민주당", "정의당", "개혁신당",
            "새누리", "자유한국당", "바른미래당", "국민의당", "열린민주당",
            "진보당", "녹색당", "기본소득당", "시대전환", "조국혁신당",
            "대통령", "윤석열", "이재명", "한동훈", "조국", "이준석", "안철수",
            "김건희", "명태균", "이낙연", "추미애", "박지원", "김종인",
            "유승민", "홍준표", "오세훈", "김기현", "나경원", "원희룡",
            "박영선", "정청래", "이해찬", "김어준", "진중권",
            "김문수", "권성동", "배현진", "장경태", "김남국", "최강욱",
            "김용태", "이재정", "박주민", "윤건영", "김의겸", "천하람",
            "문재인", "박근혜", "이명박", "노무현", "김대중", "노태우",
            "국회", "청와대", "용산", "여당", "야당", "정부", "의원", "장관", "총리",
            "헌법재판소", "헌재", "대법원", "감사원", "국정원", "경찰청",
            "검수완박", "공수처", "방통위", "선관위", "중앙선관위",
            "비서실장", "수석", "대변인", "원내대표", "당대표", "비대위",
            "선거", "정치", "탄핵", "특검", "검찰", "법원", "판결", "기소",
            "국정감사", "본회의", "법안", "입법", "정책", "외교",
            "계엄령", "비상계엄", "내란", "쿠데타", "민주주의",
            "국민청원", "시위", "집회", "촛불", "태극기",
            "언론", "기레기", "가짜뉴스", "팩트체크",
            "대선", "총선", "지방선거", "재보궐", "당내경선",
            "좌파", "우파", "보수", "진보", "여론조사", "지지율",
            "문재앙", "윤재앙", "이재앙", "쥴리", "명품백", "먹튀",
            "친일", "토착왜구", "빨갱이", "수꼴", "틀딱", "이빠",
            "국짐", "민짜", "문빠", "윤빠",
        },
        "sports": {
            "야구", "축구", "농구", "배구", "골프", "테니스", "격투기", "UFC", "복싱",
            "수영", "육상", "배드민턴", "탁구", "양궁", "사격", "펜싱", "유도", "태권도",
            "피겨", "쇼트트랙", "스키", "스노보드", "컬링", "아이스하키",
            "KBO", "K리그", "KBL", "V리그", "KPGA", "KLPGA",
            "MLB", "NPB", "EPL", "프리미어리그", "라리가", "분데스리가", "세리에A",
            "챔스", "챔피언스리그", "유로파", "컨퍼런스리그",
            "NBA", "PGA", "LPGA", "ATP", "WTA",
            "월드컵", "올림픽", "아시안게임", "WBC", "아시안컵", "유로", "코파아메리카",
            "두산", "LG", "삼성", "KIA", "SSG", "롯데", "키움", "한화", "NC", "KT",
            "전북", "울산", "포항", "수원", "대전", "인천", "서울",
            "토트넘", "맨유", "맨시티", "리버풀", "첼시", "아스날", "바르셀로나", "레알마드리드",
            "뮌헨", "바이에른", "도르트문트", "유벤투스", "인터", "밀란", "PSG",
            "다저스", "양키스", "파드리스", "애리조나",
            "손흥민", "이강인", "김민재", "황희찬", "이재성", "황인범", "정우영",
            "메시", "호날두", "음바페", "홀란드", "벨링엄", "비니시우스",
            "김하성", "오타니", "류현진", "이정후", "양현종", "김광현",
            "신유빈", "임성재", "김주형", "고진영", "박인비",
            "김도훈", "홍명보", "이강철", "류중일",
            "감독", "선수", "경기", "승리", "패배", "무승부", "골", "홈런", "타율",
            "우승", "준우승", "강등", "승격", "이적", "FA", "드래프트", "트레이드",
            "플레이오프", "포스트시즌", "정규시즌", "와일드카드", "리그우승",
            "MVP", "신인왕", "다승왕", "타격왕", "홈런왕", "득점왕", "도움왕",
            "경기력", "컨디션", "부상", "복귀", "은퇴", "입단", "방출",
        },
        "celebrity": {
            "아이돌", "배우", "가수", "연예인", "래퍼", "MC", "코미디언", "개그맨",
            "뮤지컬배우", "성우", "유튜버", "인플루언서", "크리에이터",
            "방탄", "BTS", "NCT", "세븐틴", "스트레이키즈", "엑소", "투바투",
            "에이티즈", "엔하이픈", "보이넥스트도어", "제로베이스원", "라이즈",
            "빅뱅", "샤이니", "슈퍼주니어", "2PM", "위너", "아이콘",
            "블랙핑크", "뉴진스", "에스파", "르세라핌", "아이브", "트와이스",
            "레드벨벳", "잇지", "마마무", "여자아이들", "아일릿", "키스오브라이프",
            "스테이씨", "오마이걸", "에이프릴", "다이아",
            "아이유", "태연", "비비", "청하", "소미", "선미", "제니", "로제",
            "임영웅", "영탁", "이찬원", "정동원",
            "송강호", "이병헌", "황정민", "마동석", "조인성", "공유", "현빈", "송중기",
            "이정재", "정우성", "하정우", "유아인", "박서준", "변우석", "차은우",
            "손석구", "류준열", "박보검", "이종석", "지창욱",
            "전지현", "손예진", "한소희", "김태리", "배수지", "한효주",
            "송혜교", "김고은", "전여빈", "김다미", "박은빈", "김지원", "고윤정",
            "문가영", "노윤서", "신세경", "박신혜",
            "유재석", "강호동", "이승기", "김종국", "송지효", "전소민",
            "이광수", "신동엽", "박명수", "하하", "정형돈", "황제성",
            "나영석", "김태호",
            "하이브", "SM", "JYP", "YG", "스타쉽", "큐브", "플레디스",
            "안테나", "빅히트", "어도어", "KOZ", "피네이션", "AOMG",
            "나혼산", "나혼자산다", "놀뭐", "놀면뭐하니", "런닝맨", "유퀴즈",
            "신서유기", "삼시세끼", "강철부대", "지옥",
            "SNL", "무한도전", "1박2일", "라디오스타", "아는형님",
            "드라마", "영화", "예능", "콘서트", "팬미팅", "컴백", "데뷔",
            "촬영", "개봉", "방영", "종영", "시청률",
            "팬덤", "앨범", "음원", "차트", "멜론", "지니", "벅스",
            "팬사인회", "생방송", "출연", "캐스팅", "스캔들", "열애",
            "결혼", "이혼", "임신", "출산", "사생활", "불륜", "양육권",
            "광고", "화보", "인터뷰", "V라이브", "위버스",
            "칸영화제", "아카데미", "청룡영화상", "대종상", "백상예술대상",
            "CGV", "메가박스", "롯데시네마", "박스오피스", "개봉작",
        },
        "stock": {
            "코스피", "코스닥", "나스닥", "다우지수", "S&P500",
            "증시", "주식시장", "선물시장", "옵션시장",
            "미국증시", "일본증시", "중국증시", "유럽증시",
            "삼성전자", "SK하이닉스", "네이버", "카카오", "LG에너지솔루션",
            "삼성바이오", "현대차", "기아", "셀트리온", "포스코",
            "삼성SDI", "LG화학", "삼성물산", "현대모비스", "KB금융",
            "테슬라", "엔비디아", "애플", "마이크로소프트", "구글", "아마존",
            "메타", "넷플릭스", "AMD", "인텔", "브로드컴", "ASML",
            "상장", "상폐", "배당금", "유상증자", "무상증자",
            "공매도", "상한가", "하한가", "시가총액", "PER", "PBR", "ROE",
            "매수", "매도", "개미", "기관", "외국인", "수급",
            "급등주", "급락주", "폭락", "반등", "조정", "횡보",
            "실적", "어닝", "컨센", "IR", "공시", "분기실적", "연간실적",
            "테마주", "대장주", "작전주", "잡주", "우량주", "가치주", "성장주",
            "차트", "캔들", "이평선", "지지선", "저항선", "돌파", "이탈",
            "물타기", "불타기", "손절", "익절", "본절", "존버",
            "기준금리", "금통위", "연준", "FOMC", "인플레이션", "스태그플레이션",
            "디플레이션", "경기침체", "GDP", "한국은행", "중앙은행",
            "물가", "CPI", "고용지표", "실업률", "금리인상", "금리인하",
            "양적완화", "테이퍼링", "피봇",
            "부동산", "아파트", "분양", "청약", "전세", "월세", "갭투자",
            "재개발", "재건축", "임대", "매매", "집값",
            "비트코인", "이더리움", "암호화폐", "가상화폐",
            "알트코인", "코인시장", "업비트", "바이낸스", "빗썸",
            "리플", "솔라나", "도지코인", "시바이누",
            "펀드", "ETF", "채권", "국채", "회사채", "예금", "적금",
            "보험", "연금", "IRP", "ISA",
        },
        "game": {
            "롤", "리그오브레전드", "LOL", "배그", "배틀그라운드", "PUBG",
            "오버워치", "오버워치2", "발로란트", "메이플", "메이플스토리",
            "로스트아크", "던파", "던전앤파이터", "리니지", "리니지2", "리니지W",
            "피파", "FC온라인", "서든어택", "카스", "카운터스트라이크",
            "디아블로", "디아블로4", "와우", "월드오브워크래프트", "WoW",
            "스타크래프트", "스타", "시드마이어", "문명", "롤토체스", "TFT",
            "데스티니가디언즈", "이스케이프프롬타르코프", "타르코프",
            "젤다", "젤다의전설", "마리오", "포켓몬", "팔루", "팔월드",
            "엘든링", "몬스터헌터", "몬헌", "용과같이", "페르소나",
            "파이널판타지", "FF", "킹덤하츠", "갓오브워", "라스트오브어스",
            "호라이즌", "스파이더맨", "GTA", "GTA6", "레드데드리뎀션",
            "원신", "붕괴", "붕괴스타레일", "명일방주", "블루아카이브", "블루아카",
            "우마무스메", "프린세스커넥트", "프리코네", "쿠키런", "쿠키런킹덤",
            "브롤스타즈", "클래시로얄", "클래시오브클랜",
            "리니지M", "리니지2M", "검은사막", "검은사막모바일",
            "승리의여신니케", "니케", "스타레일", "제로",
            "스팀", "Steam", "에픽게임즈", "배틀넷", "유비소프트", "EA",
            "PS5", "플스", "플스5", "닌텐도", "스위치", "엑스박스", "Xbox",
            "PC방", "피씨방", "콘솔", "플레이스테이션",
            "트위치", "아프리카TV", "아프리카", "치지직", "유튜브게임",
            "스트리머", "BJ", "VJ", "버튜버",
            "e스포츠", "이스포츠", "프로게이머", "LCK", "롤드컵", "월드챔피언십",
            "T1", "젠지", "DRX", "한화생명", "KT롤스터", "광동프릭스",
            "페이커", "데프트", "쵸비", "페이즈",
            "게임", "겜", "플레이", "패치", "업데이트", "시즌", "신캐",
            "너프", "버프", "밸런스", "메타", "티어", "픽률", "밴률",
            "레이드", "던전", "보스", "파밍", "렙업", "육성", "가챠", "뽑기",
            "스킨", "코스튬", "결제", "과금", "BM", "현질",
            "넥슨", "엔씨소프트", "엔씨", "크래프톤", "넷마블", "스마일게이트",
            "카카오게임즈", "펄어비스", "라이엇", "블리자드", "닌텐도", "소니",
            "원피스", "나루토", "블리치", "진격의거인", "귀멸의칼날", "주술회전",
            "원펀맨", "나의히어로아카데미아", "히로아카", "드래곤볼", "슬램덩크",
            "헌터x헌터", "체인소맨", "스파이패밀리", "최애의아이", "프리렌",
            "웹툰", "만화", "애니", "애니메이션", "작화", "원작",
            "네이버웹툰", "카카오웹툰", "레진코믹스", "코믹스",
            "전생", "이세계", "먼치킨", "회귀", "회귀물", "전생물",
            "디즈니", "픽사", "지브리", "주토피아", "겨울왕국", "토이스토리",
            "나는전설이다", "아바타", "메탈슬러그",
            "루피", "조로", "나미", "사스케", "카카시", "탄지로", "고죠",
            "이카리신지", "에반게리온", "에바", "건담", "원펀맨",
        },
        "issue": {
            "사건", "사고", "속보", "뉴스", "기사", "논란",
            "날씨", "태풍", "지진", "홍수", "폭우", "폭설",
            "화재", "교통사고", "범죄", "사기", "보이스피싱",
            "아이폰", "갤럭시", "컴퓨터", "노트북", "AI", "챗GPT",
            "맥북", "아이패드", "태블릿", "스마트폰", "안드로이드", "iOS",
        },
    }

    # set을 defaultdict로 변환
    result = defaultdict(set)
    for cat, words in existing.items():
        result[cat] = set(words)
        print(f"  {cat}: {len(words)}개 기존 키워드")

    return result


def merge_keywords(
    existing: Dict[str, Set[str]],
    new_wiki: Dict[str, Set[str]]
) -> Dict[str, List[str]]:
    """기존 키워드와 새 키워드 병합"""
    print("\n키워드 병합 중...")

    merged: Dict[str, Set[str]] = defaultdict(set)

    # 기존 키워드 추가
    for cat, words in existing.items():
        merged[cat].update(words)

    # 위키피디아 키워드 추가
    for cat, words in new_wiki.items():
        merged[cat].update(words)

    # 중복 키워드 처리 (여러 카테고리에 존재하는 경우)
    # CATEGORY_PRIORITY에 따라 우선 카테고리에만 유지
    CATEGORY_PRIORITY = ["celebrity", "sports", "stock", "politics", "game", "issue"]

    all_keywords: Dict[str, str] = {}  # keyword → category

    for cat in CATEGORY_PRIORITY:
        words = merged.get(cat, set())
        for word in list(words):
            if word in all_keywords:
                # 이미 다른 카테고리에 할당됨 → 현재 카테고리에서 제거
                words.discard(word)
            else:
                all_keywords[word] = cat

    # 정렬된 리스트로 변환
    result = {}
    for cat in CATEGORY_PRIORITY:
        words = merged.get(cat, set())
        result[cat] = sorted(list(words))

    return result


def generate_keywords_py(merged: Dict[str, List[str]], output_path: Path):
    """새 keywords.py 파일 생성"""
    print(f"\nkeywords.py 생성 중: {output_path}")

    lines = [
        '"""',
        '카테고리별 키워드 사전',
        '',
        '외부 리소스 출처 (라이선스 준수):',
        '- 한국어 위키피디아: CC-BY-SA-3.0 (https://ko.wikipedia.org/)',
        '- 자동 추출 스크립트: backend/scripts/extract_keywords_hf.py',
        '"""',
        '',
        'KEYWORDS = {',
    ]

    # 카테고리 순서
    CAT_ORDER = ["politics", "sports", "celebrity", "stock", "game", "issue"]
    CAT_COMMENTS = {
        "politics": "# 정치",
        "sports": "# 스포츠",
        "celebrity": "# 연예/엔터테인먼트",
        "stock": "# 경제/금융",
        "game": "# 게임/만화/애니",
        "issue": "# 일반 이슈 (fallback)",
    }

    for cat in CAT_ORDER:
        keywords = merged.get(cat, [])
        lines.append(f'    "{cat}": [  {CAT_COMMENTS.get(cat, "")}')

        # 키워드를 8개씩 한 줄에 출력
        for i in range(0, len(keywords), 8):
            chunk = keywords[i:i+8]
            quoted = ', '.join(f'"{w}"' for w in chunk)
            lines.append(f'        {quoted},')

        lines.append('    ],')

    lines.append('}')
    lines.append('')
    lines.append('# 카테고리 우선순위 (동점 시 우선 선택)')
    lines.append('CATEGORY_PRIORITY = ["celebrity", "sports", "stock", "politics", "game", "issue"]')
    lines.append('')
    lines.append('# 각 카테고리의 키워드 수 확인용')
    lines.append('CATEGORY_INFO = {cat: len(keywords) for cat, keywords in KEYWORDS.items()}')
    lines.append('')

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))

    # 통계 출력
    total = sum(len(words) for words in merged.values())
    print(f"\n{'=' * 40}")
    print(f"키워드 추출 완료")
    print(f"{'=' * 40}")
    print(f"총 키워드: {total}개")
    for cat in CAT_ORDER:
        print(f"  {cat}: {len(merged.get(cat, []))}개")


def main():
    print("=" * 50)
    print("위키피디아 키워드 추출 스크립트")
    print("=" * 50)

    # 1. 기존 키워드 로드 (하드코딩)
    existing = load_existing_keywords()

    # 2. 위키피디아에서 키워드 추출
    wiki_keywords = extract_from_wikipedia()

    # 3. 키워드 병합
    merged = merge_keywords(existing, wiki_keywords)

    # 4. 새 keywords.py 생성
    output_path = Path(__file__).parent.parent / "ai" / "keywords.py"
    generate_keywords_py(merged, output_path)

    print("\n완료! keywords.py가 업데이트되었습니다.")
    print("python main.py --classify 명령으로 분류 테스트를 실행하세요.")


if __name__ == "__main__":
    main()
